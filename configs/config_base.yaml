seed: 42
run_name: run-01

# WHAT we train
mode: sft               # allowed: sft | cpt | cpt_mixed

# Packing for CPT/DAPT (safe defaults; ignored by sft mode)
block_size: 2048
pack_factor: 4

# Optional multi-dataset list used when mode=cpt_mixed
datasets: []            # e.g. defined in run_dapt.yaml

# Common model configuration
model:
  name: Qwen/Qwen2.5-1.5B-Instruct     # HF repo_id OR local folder path
  local_dir: models/Qwen-Qwen2.5-1.5B-Instruct       # where to store/download the model
  revision: main                        # optional: tag/sha
  trust_remote_code: true               # some repos need this
  type: causal
  max_seq_len: 512

# Common tuning configuration
tuning:
  mode: qlora          # qlora | lora | full
  backend: bnb         # default backend, can be overridden
  lora:
    r: 32
    alpha: 64
    dropout: 0.05
    target_modules: auto

train:
  epochs: 3
  learning_rate: 2e-4
  weight_decay: 0.01
  lr_scheduler_type: cosine           # valid values: linear, cosine, cosine_with_restarts, polynomial, constant, constant_with_warmup
  warmup_ratio: 0.06                  # or set num_warmup_steps instead
  optim: adamw_torch

  # precision & memory (can be overridden per backend)
  bf16: true
  fp16: false
  gradient_checkpointing: true
  batch_size: auto
  grad_accum: auto

  # logging / eval / save
  logging_steps: 1                    # see frequent logs in TB
  evaluation_strategy: steps          # HF name in 4.55 is evaluation_strategy
  eval_steps: 10                      # evaluate every 10 steps to avoid OOM
  save_strategy: steps
  save_steps: 10                      # save periodically without spamming
  save_total_limit: 3
  load_best_model_at_end: true
  metric_for_best_model: eval_loss
  greater_is_better: false

  output_dir: outputs/run-01

data:
  format: chat
  template_path: chat_templates/default.jinja
  train_path: data/processed/train.jsonl
  val_path:   data/processed/val.jsonl
  test_path:  data/processed/test.jsonl
  cache_dir: data/cache
  split:
    train_ratio: 0.7
    val_ratio: 0.1
    test_ratio: 0.2

logging:
  backend: tensorboard
  log_interval: 1
