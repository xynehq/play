# Model Configuration File
# This file contains model details for benchmark testing

# API Configuration
api_base: "API_BASE"  # e.g., "https://api.yourmodel.com/v1"

# Model Names - choose which model to test
model_name: "MODEL_NAME"


# API Authentication (optional)
api_key: ""  # Leave blank if not required

# Benchmark Settings
benchmark:
  edit_format: "whole"  # Options: whole, diff, udiff
  threads: 1           # Number of parallel threads
  tries: 2             # Number of retries per test
  num_tests: null       # Number of tests to run (null for all)
  language: "1"       # Options: 1. All languages, 2. C++, 3. Go, 4. Java, 5. JavaScript, 6. Python, 7. Rust
  keywords: null        # Additional keyword filter (optional)

max_iterations: 100 #For SWE-Bench
temperature: 0.0     
top_p: 0.95         

k_values: [1] # For Archit Eval
archit_n: 1 # For Archit Eval
archit_dataset: "archit11/evals"
max_examples: 300 # For Archit Eval
max_tokens: 2048 # For Archit Eval
archit_split: "train" # For Archit Eval
archit_output: "eval_results_litellm.json" # For Archit Eval

rust_evo_setup: 1 # For RustEvo setup 
    # 1. Full Setup (Install dependencies + Run both RQ1 & RQ3)
    # 2. Install Dependencies Only
    # 3. Run RQ1 Only (Full Documentation)
    # 4. Run RQ3 Only (Minimal Documentation)
    # 5. Run Both RQ1 & RQ3
    # 6. Exit
workers: 8    # For RustEvo setup